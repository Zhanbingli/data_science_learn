{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - å•å˜é‡åˆ†æ\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "- æŒæ¡æ•°å€¼å‹å˜é‡çš„åˆ†å¸ƒåˆ†ææ–¹æ³•\n",
    "- æŒæ¡ç±»åˆ«å‹å˜é‡çš„é¢‘æ•°åˆ†æ\n",
    "- å­¦ä¼šä½¿ç”¨å¤šç§å¯è§†åŒ–æ–¹æ³•å±•ç¤ºå•å˜é‡ç‰¹å¾\n",
    "\n",
    "## ğŸ“š æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
    "1. **æ•°å€¼å‹å˜é‡åˆ†æ**\n",
    "   - ç›´æ–¹å›¾ï¼ˆHistogramï¼‰ï¼šè§‚å¯Ÿåˆ†å¸ƒå½¢æ€\n",
    "   - ç®±çº¿å›¾ï¼ˆBoxplotï¼‰ï¼šè¯†åˆ«å¼‚å¸¸å€¼\n",
    "   - å¯†åº¦å›¾ï¼ˆKDEï¼‰ï¼šå¹³æ»‘çš„åˆ†å¸ƒæ›²çº¿\n",
    "   - QQå›¾ï¼šæ£€éªŒæ­£æ€æ€§\n",
    "\n",
    "2. **ç±»åˆ«å‹å˜é‡åˆ†æ**\n",
    "   - é¢‘æ•°ç»Ÿè®¡\n",
    "   - æŸ±çŠ¶å›¾/é¥¼å›¾\n",
    "   - é«˜åŸºæ•°ç±»åˆ«ç‰¹å¾å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# å¯¼å…¥åº“\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# é…ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "train = pd.read_pickle('../../data/processed/train_initial.pkl')\n",
    "print(f\"æ•°æ®å½¢çŠ¶: {train.shape}\")\n",
    "\n",
    "# åˆ†ç¦»ç‰¹å¾ç±»å‹\n",
    "numeric_features = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# å‡è®¾ç›®æ ‡å˜é‡\n",
    "TARGET_COL = 'target'  # æ ¹æ®å®é™…ä¿®æ”¹\n",
    "if TARGET_COL in numeric_features:\n",
    "    numeric_features.remove(TARGET_COL)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. æ•°å€¼å‹å˜é‡åˆ†æ\n",
    "\n",
    "### ğŸ’¡ å­¦ä¹ è¦ç‚¹\n",
    "- **ååº¦ï¼ˆSkewnessï¼‰**ï¼šåˆ†å¸ƒçš„å¯¹ç§°æ€§\n",
    "  - ååº¦ = 0ï¼šæ­£æ€åˆ†å¸ƒ\n",
    "  - ååº¦ > 0ï¼šå³åï¼ˆé•¿å°¾åœ¨å³ï¼‰\n",
    "  - ååº¦ < 0ï¼šå·¦åï¼ˆé•¿å°¾åœ¨å·¦ï¼‰\n",
    "  \n",
    "- **å³°åº¦ï¼ˆKurtosisï¼‰**ï¼šåˆ†å¸ƒçš„é™¡å³­ç¨‹åº¦\n",
    "  - å³°åº¦ = 3ï¼šæ­£æ€åˆ†å¸ƒ\n",
    "  - å³°åº¦ > 3ï¼šå°–å³°\n",
    "  - å³°åº¦ < 3ï¼šå¹³å³°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_numeric_feature(df, feature):\n",
    "    \"\"\"åˆ†æå•ä¸ªæ•°å€¼å‹ç‰¹å¾\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'ç‰¹å¾: {feature}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. ç›´æ–¹å›¾ + KDE\n",
    "    axes[0, 0].hist(df[feature].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].set_title('ç›´æ–¹å›¾')\n",
    "    axes[0, 0].set_xlabel(feature)\n",
    "    axes[0, 0].set_ylabel('é¢‘æ•°')\n",
    "    \n",
    "    # 2. å¯†åº¦å›¾\n",
    "    df[feature].dropna().plot(kind='kde', ax=axes[0, 1], linewidth=2)\n",
    "    axes[0, 1].set_title('æ ¸å¯†åº¦ä¼°è®¡ (KDE)')\n",
    "    axes[0, 1].set_xlabel(feature)\n",
    "    \n",
    "    # 3. ç®±çº¿å›¾\n",
    "    axes[1, 0].boxplot(df[feature].dropna(), vert=False)\n",
    "    axes[1, 0].set_title('ç®±çº¿å›¾ï¼ˆæ£€æµ‹å¼‚å¸¸å€¼ï¼‰')\n",
    "    axes[1, 0].set_xlabel(feature)\n",
    "    \n",
    "    # 4. QQå›¾ï¼ˆæ­£æ€æ€§æ£€éªŒï¼‰\n",
    "    stats.probplot(df[feature].dropna(), dist=\"norm\", plot=axes[1, 1])\n",
    "    axes[1, 1].set_title('QQå›¾ï¼ˆæ­£æ€æ€§æ£€éªŒï¼‰')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ç‰¹å¾: {feature}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"ç¼ºå¤±å€¼: {df[feature].isnull().sum()} ({df[feature].isnull().sum()/len(df)*100:.2f}%)\")\n",
    "    print(f\"å”¯ä¸€å€¼æ•°é‡: {df[feature].nunique()}\")\n",
    "    print(f\"\\næè¿°æ€§ç»Ÿè®¡:\")\n",
    "    print(df[feature].describe())\n",
    "    print(f\"\\nååº¦ (Skewness): {df[feature].skew():.4f}\")\n",
    "    print(f\"å³°åº¦ (Kurtosis): {df[feature].kurtosis():.4f}\")\n",
    "    \n",
    "    # å¼‚å¸¸å€¼ç»Ÿè®¡ï¼ˆIQRæ–¹æ³•ï¼‰\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "    print(f\"\\nå¼‚å¸¸å€¼æ•°é‡ (IQRæ–¹æ³•): {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ç¤ºä¾‹ï¼šåˆ†æç¬¬ä¸€ä¸ªæ•°å€¼å‹ç‰¹å¾\n",
    "if len(numeric_features) > 0:\n",
    "    analyze_numeric_feature(train, numeric_features[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‰¹é‡åˆ†ææ‰€æœ‰æ•°å€¼å‹ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åˆ›å»ºç»Ÿè®¡æ‘˜è¦è¡¨\n",
    "numeric_summary = pd.DataFrame({\n",
    "    'ç‰¹å¾': numeric_features,\n",
    "    'ç¼ºå¤±ç‡': [train[col].isnull().sum() / len(train) * 100 for col in numeric_features],\n",
    "    'å”¯ä¸€å€¼': [train[col].nunique() for col in numeric_features],\n",
    "    'å‡å€¼': [train[col].mean() for col in numeric_features],\n",
    "    'æ ‡å‡†å·®': [train[col].std() for col in numeric_features],\n",
    "    'æœ€å°å€¼': [train[col].min() for col in numeric_features],\n",
    "    'æœ€å¤§å€¼': [train[col].max() for col in numeric_features],\n",
    "    'ååº¦': [train[col].skew() for col in numeric_features],\n",
    "    'å³°åº¦': [train[col].kurtosis() for col in numeric_features]\n",
    "})\n",
    "\n",
    "numeric_summary.round(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯è§†åŒ–æ‰€æœ‰æ•°å€¼å‹ç‰¹å¾åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ç»˜åˆ¶æ‰€æœ‰æ•°å€¼å‹ç‰¹å¾çš„ç›´æ–¹å›¾\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_features) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(numeric_features):\n",
    "    train[feature].hist(bins=50, ax=axes[idx], edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'{feature}\\nååº¦: {train[feature].skew():.2f}')\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "# éšè—å¤šä½™çš„å­å›¾\n",
    "for idx in range(len(numeric_features), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('æ‰€æœ‰æ•°å€¼å‹ç‰¹å¾åˆ†å¸ƒ', fontsize=16, y=1.001)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ç±»åˆ«å‹å˜é‡åˆ†æ\n",
    "\n",
    "### ğŸ’¡ å­¦ä¹ è¦ç‚¹\n",
    "- é«˜åŸºæ•°ç±»åˆ«ç‰¹å¾ï¼šå”¯ä¸€å€¼å¾ˆå¤šçš„ç±»åˆ«ç‰¹å¾\n",
    "- ç±»åˆ«ä¸å¹³è¡¡ï¼šæŸäº›ç±»åˆ«æ ·æœ¬é‡è¿œå¤§äºå…¶ä»–ç±»åˆ«\n",
    "- ç¨€æœ‰ç±»åˆ«ï¼šå‡ºç°æ¬¡æ•°å¾ˆå°‘çš„ç±»åˆ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_categorical_feature(df, feature, top_n=10):\n",
    "    \"\"\"åˆ†æå•ä¸ªç±»åˆ«å‹ç‰¹å¾\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    fig.suptitle(f'ç‰¹å¾: {feature}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # é¢‘æ•°ç»Ÿè®¡\n",
    "    value_counts = df[feature].value_counts()\n",
    "    \n",
    "    # 1. æŸ±çŠ¶å›¾ï¼ˆæ˜¾ç¤ºTop Nï¼‰\n",
    "    value_counts.head(top_n).plot(kind='barh', ax=axes[0])\n",
    "    axes[0].set_title(f'Top {top_n} ç±»åˆ«é¢‘æ•°')\n",
    "    axes[0].set_xlabel('é¢‘æ•°')\n",
    "    \n",
    "    # 2. å æ¯”å›¾\n",
    "    value_pct = df[feature].value_counts(normalize=True) * 100\n",
    "    value_pct.head(top_n).plot(kind='barh', ax=axes[1])\n",
    "    axes[1].set_title(f'Top {top_n} ç±»åˆ«å æ¯”')\n",
    "    axes[1].set_xlabel('å æ¯” (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ç‰¹å¾: {feature}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"ç¼ºå¤±å€¼: {df[feature].isnull().sum()} ({df[feature].isnull().sum()/len(df)*100:.2f}%)\")\n",
    "    print(f\"å”¯ä¸€å€¼æ•°é‡: {df[feature].nunique()}\")\n",
    "    print(f\"\\nTop 10 ç±»åˆ«:\")\n",
    "    top_10 = pd.DataFrame({\n",
    "        'ç±»åˆ«': value_counts.head(10).index,\n",
    "        'é¢‘æ•°': value_counts.head(10).values,\n",
    "        'å æ¯”(%)': value_pct.head(10).values\n",
    "    })\n",
    "    print(top_10.to_string(index=False))\n",
    "    \n",
    "    # ç¨€æœ‰ç±»åˆ«ç»Ÿè®¡\n",
    "    rare_threshold = 0.01  # å‡ºç°é¢‘ç‡å°äº1%\n",
    "    rare_categories = value_pct[value_pct < rare_threshold * 100]\n",
    "    print(f\"\\nç¨€æœ‰ç±»åˆ«ï¼ˆ<1%ï¼‰: {len(rare_categories)} ä¸ª\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ç¤ºä¾‹ï¼šåˆ†æç¬¬ä¸€ä¸ªç±»åˆ«å‹ç‰¹å¾\n",
    "if len(categorical_features) > 0:\n",
    "    analyze_categorical_feature(train, categorical_features[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‰¹é‡åˆ†ææ‰€æœ‰ç±»åˆ«å‹ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åˆ›å»ºç±»åˆ«å‹ç‰¹å¾æ‘˜è¦è¡¨\n",
    "categorical_summary = pd.DataFrame({\n",
    "    'ç‰¹å¾': categorical_features,\n",
    "    'ç¼ºå¤±ç‡': [train[col].isnull().sum() / len(train) * 100 for col in categorical_features],\n",
    "    'å”¯ä¸€å€¼': [train[col].nunique() for col in categorical_features],\n",
    "    'æœ€å¸¸è§ç±»åˆ«': [train[col].mode()[0] if len(train[col].mode()) > 0 else None for col in categorical_features],\n",
    "    'æœ€å¸¸è§ç±»åˆ«å æ¯”': [train[col].value_counts(normalize=True).iloc[0] * 100 if len(train[col].value_counts()) > 0 else 0 for col in categorical_features]\n",
    "})\n",
    "\n",
    "categorical_summary.round(2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. è¯†åˆ«éœ€è¦ç‰¹æ®Šå¤„ç†çš„ç‰¹å¾\n",
    "\n",
    "### ğŸ’¡ å…³é”®åˆ¤æ–­æ ‡å‡†\n",
    "1. **é«˜ååº¦ç‰¹å¾**ï¼ˆ|skewness| > 1ï¼‰ï¼šè€ƒè™‘å¯¹æ•°å˜æ¢\n",
    "2. **é«˜ç¼ºå¤±ç‡ç‰¹å¾**ï¼ˆ>50%ï¼‰ï¼šè€ƒè™‘åˆ é™¤æˆ–ç‰¹æ®Šå¤„ç†\n",
    "3. **å¸¸æ•°ç‰¹å¾**ï¼šå”¯ä¸€å€¼=1ï¼Œåº”åˆ é™¤\n",
    "4. **é«˜åŸºæ•°ç±»åˆ«ç‰¹å¾**ï¼šè€ƒè™‘é¢‘æ•°ç¼–ç æˆ–ç›®æ ‡ç¼–ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"ç‰¹å¾è¯Šæ–­æŠ¥å‘Š\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. é«˜ååº¦ç‰¹å¾\n",
    "high_skew_features = numeric_summary[numeric_summary['ååº¦'].abs() > 1]['ç‰¹å¾'].tolist()\n",
    "print(f\"\\n1. é«˜ååº¦ç‰¹å¾ (|skew| > 1): {len(high_skew_features)} ä¸ª\")\n",
    "if high_skew_features:\n",
    "    print(f\"   {high_skew_features}\")\n",
    "    print(\"   å»ºè®®: è€ƒè™‘å¯¹æ•°å˜æ¢æˆ–Box-Coxå˜æ¢\")\n",
    "\n",
    "# 2. é«˜ç¼ºå¤±ç‡ç‰¹å¾\n",
    "high_missing_numeric = numeric_summary[numeric_summary['ç¼ºå¤±ç‡'] > 50]['ç‰¹å¾'].tolist()\n",
    "high_missing_categorical = categorical_summary[categorical_summary['ç¼ºå¤±ç‡'] > 50]['ç‰¹å¾'].tolist()\n",
    "high_missing_features = high_missing_numeric + high_missing_categorical\n",
    "print(f\"\\n2. é«˜ç¼ºå¤±ç‡ç‰¹å¾ (>50%): {len(high_missing_features)} ä¸ª\")\n",
    "if high_missing_features:\n",
    "    print(f\"   {high_missing_features}\")\n",
    "    print(\"   å»ºè®®: è€ƒè™‘åˆ é™¤æˆ–å°†ç¼ºå¤±ä½œä¸ºæ–°ç±»åˆ«\")\n",
    "\n",
    "# 3. å¸¸æ•°ç‰¹å¾\n",
    "constant_features = [col for col in train.columns if train[col].nunique() == 1]\n",
    "print(f\"\\n3. å¸¸æ•°ç‰¹å¾: {len(constant_features)} ä¸ª\")\n",
    "if constant_features:\n",
    "    print(f\"   {constant_features}\")\n",
    "    print(\"   å»ºè®®: åˆ é™¤ï¼Œæ— ä¿¡æ¯é‡\")\n",
    "\n",
    "# 4. é«˜åŸºæ•°ç±»åˆ«ç‰¹å¾\n",
    "high_cardinality_features = categorical_summary[categorical_summary['å”¯ä¸€å€¼'] > 50]['ç‰¹å¾'].tolist()\n",
    "print(f\"\\n4. é«˜åŸºæ•°ç±»åˆ«ç‰¹å¾ (å”¯ä¸€å€¼>50): {len(high_cardinality_features)} ä¸ª\")\n",
    "if high_cardinality_features:\n",
    "    print(f\"   {high_cardinality_features}\")\n",
    "    print(\"   å»ºè®®: é¢‘æ•°ç¼–ç ã€ç›®æ ‡ç¼–ç æˆ–åˆ†ç»„\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ æœ¬èŠ‚æ€»ç»“\n",
    "\n",
    "### å·²å®Œæˆçš„å·¥ä½œ\n",
    "- [ ] æ•°å€¼å‹ç‰¹å¾çš„åˆ†å¸ƒåˆ†æ\n",
    "- [ ] ç±»åˆ«å‹ç‰¹å¾çš„é¢‘æ•°åˆ†æ\n",
    "- [ ] è¯†åˆ«å¼‚å¸¸å€¼å’Œåæ€åˆ†å¸ƒ\n",
    "- [ ] è¯†åˆ«éœ€è¦ç‰¹æ®Šå¤„ç†çš„ç‰¹å¾\n",
    "\n",
    "### å…³é”®å‘ç°\n",
    "è®°å½•ä½ çš„å‘ç°ï¼š\n",
    "1. å“ªäº›ç‰¹å¾å‘ˆæ­£æ€åˆ†å¸ƒï¼Ÿ\n",
    "2. å“ªäº›ç‰¹å¾æœ‰ä¸¥é‡çš„åæ€ï¼Ÿ\n",
    "3. å“ªäº›ç±»åˆ«ç‰¹å¾ä¸å¹³è¡¡ï¼Ÿ\n",
    "4. æœ‰å“ªäº›å¼‚å¸¸å€¼éœ€è¦å¤„ç†ï¼Ÿ\n",
    "\n",
    "### ä¸‹ä¸€æ­¥è®¡åˆ’\n",
    "- åŒå˜é‡åˆ†æï¼šæ¢ç´¢ç‰¹å¾ä¸ç›®æ ‡çš„å…³ç³»\n",
    "- å¤šå˜é‡åˆ†æï¼šç‰¹å¾é—´çš„ç›¸å…³æ€§"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
