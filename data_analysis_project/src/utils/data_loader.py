"""
æ•°æ®åŠ è½½å·¥å…·æ¨¡å—
æä¾›æ ‡å‡†åŒ–çš„æ•°æ®è¯»å–å’Œåˆæ­¥å¤„ç†åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from pathlib import Path
import yaml
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataLoader:
    """æ•°æ®åŠ è½½å™¨ç±»"""

    def __init__(self, config_path='config/config.yaml'):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨

        Parameters:
        -----------
        config_path : str
            é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.data_dir = Path(self.config['data']['raw_dir'])

    def _load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def load_train_data(self, **kwargs):
        """
        åŠ è½½è®­ç»ƒæ•°æ®

        Parameters:
        -----------
        **kwargs : dict
            pd.read_csvçš„é¢å¤–å‚æ•°

        Returns:
        --------
        pd.DataFrame
            è®­ç»ƒæ•°æ®
        """
        train_file = self.data_dir / self.config['data']['train_file']
        logger.info(f"åŠ è½½è®­ç»ƒæ•°æ®: {train_file}")

        df = pd.read_csv(train_file, **kwargs)
        logger.info(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {df.shape}")

        return df

    def load_test_data(self, **kwargs):
        """
        åŠ è½½æµ‹è¯•æ•°æ®

        Parameters:
        -----------
        **kwargs : dict
            pd.read_csvçš„é¢å¤–å‚æ•°

        Returns:
        --------
        pd.DataFrame
            æµ‹è¯•æ•°æ®
        """
        test_file = self.data_dir / self.config['data']['test_file']
        logger.info(f"åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")

        df = pd.read_csv(test_file, **kwargs)
        logger.info(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {df.shape}")

        return df

    def load_data(self, file_path, **kwargs):
        """
        åŠ è½½æŒ‡å®šè·¯å¾„çš„æ•°æ®

        Parameters:
        -----------
        file_path : str or Path
            æ•°æ®æ–‡ä»¶è·¯å¾„
        **kwargs : dict
            pd.read_csvçš„é¢å¤–å‚æ•°

        Returns:
        --------
        pd.DataFrame
            æ•°æ®
        """
        logger.info(f"åŠ è½½æ•°æ®: {file_path}")
        df = pd.read_csv(file_path, **kwargs)
        logger.info(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        return df

    def get_data_info(self, df):
        """
        è·å–æ•°æ®åŸºæœ¬ä¿¡æ¯

        Parameters:
        -----------
        df : pd.DataFrame
            æ•°æ®æ¡†

        Returns:
        --------
        dict
            æ•°æ®ä¿¡æ¯å­—å…¸
        """
        info = {
            'shape': df.shape,
            'n_rows': len(df),
            'n_cols': len(df.columns),
            'columns': df.columns.tolist(),
            'dtypes': df.dtypes.to_dict(),
            'memory_usage': df.memory_usage(deep=True).sum() / 1024**2,  # MB
            'missing_values': df.isnull().sum().to_dict(),
            'missing_percentage': (df.isnull().sum() / len(df) * 100).to_dict(),
            'duplicate_rows': df.duplicated().sum(),
        }

        # ç»Ÿè®¡ä¸åŒç±»å‹çš„ç‰¹å¾æ•°é‡
        numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_features = df.select_dtypes(include=['object']).columns.tolist()

        info['n_numeric_features'] = len(numeric_features)
        info['n_categorical_features'] = len(categorical_features)
        info['numeric_features'] = numeric_features
        info['categorical_features'] = categorical_features

        return info

    def print_data_summary(self, df, name='æ•°æ®é›†'):
        """
        æ‰“å°æ•°æ®æ‘˜è¦ä¿¡æ¯

        Parameters:
        -----------
        df : pd.DataFrame
            æ•°æ®æ¡†
        name : str
            æ•°æ®é›†åç§°
        """
        info = self.get_data_info(df)

        print("=" * 80)
        print(f"{name} - æ•°æ®æ‘˜è¦")
        print("=" * 80)
        print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"   å½¢çŠ¶: {info['shape']} (è¡Œ Ã— åˆ—)")
        print(f"   å†…å­˜å ç”¨: {info['memory_usage']:.2f} MB")
        print(f"   é‡å¤è¡Œ: {info['duplicate_rows']} è¡Œ")

        print(f"\nğŸ“ˆ ç‰¹å¾ç±»å‹:")
        print(f"   æ•°å€¼å‹ç‰¹å¾: {info['n_numeric_features']} ä¸ª")
        print(f"   ç±»åˆ«å‹ç‰¹å¾: {info['n_categorical_features']} ä¸ª")

        print(f"\nâ“ ç¼ºå¤±å€¼ç»Ÿè®¡:")
        missing_cols = {k: v for k, v in info['missing_percentage'].items() if v > 0}
        if missing_cols:
            for col, pct in sorted(missing_cols.items(), key=lambda x: x[1], reverse=True):
                print(f"   {col}: {info['missing_values'][col]} ({pct:.2f}%)")
        else:
            print("   âœ… æ— ç¼ºå¤±å€¼")

        print("=" * 80)


def reduce_mem_usage(df, verbose=True):
    """
    å‡å°‘DataFrameçš„å†…å­˜å ç”¨

    Parameters:
    -----------
    df : pd.DataFrame
        æ•°æ®æ¡†
    verbose : bool
        æ˜¯å¦æ‰“å°ä¿¡æ¯

    Returns:
    --------
    pd.DataFrame
        ä¼˜åŒ–åçš„æ•°æ®æ¡†
    """
    start_mem = df.memory_usage().sum() / 1024**2

    for col in df.columns:
        col_type = df[col].dtype

        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()

            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)

    end_mem = df.memory_usage().sum() / 1024**2

    if verbose:
        logger.info(f'å†…å­˜ä½¿ç”¨ä» {start_mem:.2f} MB é™è‡³ {end_mem:.2f} MB '
                   f'(å‡å°‘ {100 * (start_mem - end_mem) / start_mem:.1f}%)')

    return df


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    loader = DataLoader()

    # åŠ è½½æ•°æ®
    train = loader.load_train_data()
    test = loader.load_test_data()

    # æ‰“å°æ‘˜è¦
    loader.print_data_summary(train, 'è®­ç»ƒé›†')
    loader.print_data_summary(test, 'æµ‹è¯•é›†')

    # å†…å­˜ä¼˜åŒ–
    train = reduce_mem_usage(train)
    test = reduce_mem_usage(test)
